{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uE0gPlS8F8se"
      },
      "outputs": [],
      "source": [
        "!apt-get install aria2 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tHhuCqgPkWu2"
      },
      "outputs": [],
      "source": [
        "!aria2c -x 16 -s 16 https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip > /dev/null \n",
        "!aria2c -x 16 -s 16 https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J4A0K_xGke3G"
      },
      "outputs": [],
      "source": [
        "!unzip /content/Flickr8k_Dataset.zip > /dev/null\n",
        "!unzip /content/Flickr8k_text.zip > /dev/null\n",
        "!rm *.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "90iBg2gPk0Nj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "import numpy as np\n",
        "import collections\n",
        "from PIL import Image\n",
        "from textwrap import wrap\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras_preprocessing.image import load_img, img_to_array\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Embedding, LSTM, add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3PmPwuAYtG-K"
      },
      "outputs": [],
      "source": [
        "def clean_description(desc, stopwords):\n",
        "\n",
        "  cleaned = desc.lower()\n",
        "  cleaned = re.sub('[^a-z]',' ',cleaned)\n",
        "  tokens = cleaned.split(' ')\n",
        "  cleaned = ' '.join([w for w in tokens if w not in stopwords and len(w)>1])\n",
        "  \n",
        "  return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iGQkoXDG9DkU"
      },
      "outputs": [],
      "source": [
        "def get_vocabulary(dictionary):\n",
        "  vocab = set()\n",
        "\n",
        "  for desc_list in dictionary.values():\n",
        "    for desc in desc_list:\n",
        "      words = desc.split(' ')\n",
        "      for word in words:\n",
        "        vocab.add(word)\n",
        "\n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XCalBEoylB14"
      },
      "outputs": [],
      "source": [
        "with open('/content/Flickr8k.token.txt', 'r') as f:\n",
        "  all_desc = f.read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1L_H2rQ9a6G"
      },
      "outputs": [],
      "source": [
        "# Some sample data\n",
        "all_desc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wq_lrPpaxJb7"
      },
      "outputs": [],
      "source": [
        "stopwords = ['is', 'an', 'a', 'the', 'was']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DROwNiW4l-5v"
      },
      "outputs": [],
      "source": [
        "all_dict = dict()\n",
        "\n",
        "for desc in all_desc:\n",
        "  if len(desc) < 1:\n",
        "    continue\n",
        "  file_name, file_desc = desc.split('\\t')[0].split('.')[0], desc.split('\\t')[1]\n",
        "  \n",
        "  if file_name not in all_dict.keys():\n",
        "    all_dict[file_name] = []\n",
        "\n",
        "  cleaned_desc = clean_description(file_desc, stopwords)\n",
        "  cleaned_desc = 'startseq ' + cleaned_desc + ' endseq'\n",
        "\n",
        "  all_dict[file_name].append(cleaned_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i_0Jtzw-84QP"
      },
      "outputs": [],
      "source": [
        "vocab = get_vocabulary(all_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW3lc75R-P7W"
      },
      "outputs": [],
      "source": [
        "print('Total images:', len(all_dict))\n",
        "print('Total vocabulary without stopwords:', len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfXWf57k5Fpo"
      },
      "outputs": [],
      "source": [
        "!wget https://logos.flamingtext.com/Name-Logos/Bri-design-china-name.png > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ebTxnZS9E9BL"
      },
      "outputs": [],
      "source": [
        "mask = np.array(Image.open('Bri-design-china-name.png'))\n",
        "\n",
        "wordcloud = WordCloud(width = 500, height = 400, \n",
        "                  background_color ='black', \n",
        "                  min_font_size = 2,\n",
        "                  mask=mask, random_state=0).generate(' '.join(vocab)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KI6YtaLF1VI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10, 10), facecolor = 'k', edgecolor = 'k' ) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uOciJ0yu_Bio"
      },
      "outputs": [],
      "source": [
        "all_sent_list = [item.strip('startseq').strip('endseq').strip(' ') for sublist in list(all_dict.values()) for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xI_MKJE_1EJ9"
      },
      "outputs": [],
      "source": [
        "all_sent_len = [len(sent) for sent in all_sent_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-PHHK7C1zB2"
      },
      "outputs": [],
      "source": [
        "plt.hist([len(sentence.split()) for sentence in all_sent_list])\n",
        "plt.xlabel('Number of words')\n",
        "plt.ylabel('Number of sentenes')\n",
        "plt.title('Count of number of words in sentences')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahV3mMBH4Apx"
      },
      "outputs": [],
      "source": [
        "avg_sent_len = int(np.mean([len(sentence.split()) for sentence in all_sent_list]))\n",
        "avg_sent_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N4vVqL59BEZf"
      },
      "outputs": [],
      "source": [
        "words = [w for a in all_sent_list for w in a.split(' ')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4bsFEo3B66w"
      },
      "outputs": [],
      "source": [
        "counts = collections.Counter(words)\n",
        "most_common = counts.most_common()\n",
        "most_common[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7gDZDauHv_-q"
      },
      "outputs": [],
      "source": [
        "keys = [tupl[0] for tupl in most_common][:15]\n",
        "values = [tupl[1] for tupl in most_common][:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm3DmQKhxvft"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.bar(keys, values)\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Frequency of most common words')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1jiMKDFFIxk"
      },
      "outputs": [],
      "source": [
        "lengths = set()\n",
        "for cap_list in all_dict.values():\n",
        "  lengths.add(len(cap_list))\n",
        "\n",
        "print('Number of captions for each image: ', lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsZfd6iQvhGl"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Sample images', fontsize=20)\n",
        "\n",
        "zoom = 3\n",
        "w, h = fig.get_size_inches()\n",
        "fig.set_size_inches(w * zoom, h * zoom)\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(1, 26):\n",
        "  ax = fig.add_subplot(5, 5, i)\n",
        "  ax.imshow(plt.imread('Flicker8k_Dataset/'+list(all_dict.keys())[i-1]+'.jpg'))\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vgTk_q51doU"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Sample images with one of the captions', fontsize=20)\n",
        "\n",
        "zoom = 2\n",
        "w, h = fig.get_size_inches()\n",
        "fig.set_size_inches(w * zoom, h * zoom)\n",
        "\n",
        "for i in range(1, 5):\n",
        "  ax = fig.add_subplot(2, 2, i)\n",
        "  ax.imshow(plt.imread('Flicker8k_Dataset/'+list(all_dict.keys())[i-1]+'.jpg'))\n",
        "  title = ax.set_title('\\n'.join(wrap(all_dict.get(list(all_dict.keys())[i-1])[0], 60)))\n",
        "  fig.tight_layout(h_pad=2)\n",
        "  title.set_y(1.05)\n",
        "  plt.axis('off')\n",
        "  fig.subplots_adjust(top=0.85, hspace=0.3)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWVtKK1gcxwQ"
      },
      "outputs": [],
      "source": [
        "xcep = Xception(include_top=False, pooling='avg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWz_Rq80ehzF"
      },
      "outputs": [],
      "source": [
        "xcep.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBlWJSGUjTML"
      },
      "outputs": [],
      "source": [
        "predictions = dict()\n",
        "\n",
        "for dirpath, dirname, files in os.walk('Flicker8k_Dataset'):\n",
        "  for filename in tqdm(files):\n",
        "    img_path = os.path.join(dirpath, filename)\n",
        "    if os.path.isfile(img_path):\n",
        "      img = Image.open(img_path)\n",
        "      img = img.resize((299,299))\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      img = img/127.5\n",
        "      img = img - 1.0\n",
        "\n",
        "      predictions[filename.split('.')[0]] = xcep.predict(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F3ernO6VXOA"
      },
      "outputs": [],
      "source": [
        "print('Number of extracted features:', len(predictions.get(list(predictions.keys())[0])[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ObDY48VItP"
      },
      "outputs": [],
      "source": [
        "predictions.get(list(predictions.keys())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ProzimuF4K5G"
      },
      "outputs": [],
      "source": [
        "def create_list(dictionary):\n",
        "  final_list = []\n",
        "\n",
        "  for desc_list in dictionary.values():\n",
        "    for desc in desc_list:\n",
        "      final_list.append(desc)\n",
        "\n",
        "  return final_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WSKMOMxW8tp7"
      },
      "outputs": [],
      "source": [
        "def fit_tokenizer(dictionary):\n",
        "  desc_list = create_list(dictionary)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(desc_list)\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MgPqfPLZfcxJ"
      },
      "outputs": [],
      "source": [
        "def convert_to_input(tokens, pos, im_name, max_len, vocab_len, tokenizer, img_predictions):\n",
        "\n",
        "  inp = tokens[:pos]\n",
        "  out = tokens[pos]\n",
        "  inp = pad_sequences(sequences=[inp], maxlen=max_len)[0]\n",
        "  out = to_categorical(y=[out], num_classes=vocab_len, dtype='bool')[0]\n",
        "  \n",
        "  return img_predictions.get(im_name)[0], inp, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iv2Uf4bQwIL7"
      },
      "outputs": [],
      "source": [
        "def convert_all_to_input(dictionary, max_len, vocab_len, tokenizer, img_predictions):\n",
        "  \n",
        "  X_1 = list()\n",
        "  X_2 = list()\n",
        "  y = list()\n",
        "\n",
        "  for im_name, descriptions in tqdm(dictionary.items()):\n",
        "    if im_name in img_predictions.keys():\n",
        "      for desc in descriptions:\n",
        "          tokens = tokenizer.texts_to_sequences([desc])[0]\n",
        "          for i in range(1, len(tokens)):\n",
        "              _X_1, _X_2, _y = convert_to_input(tokens, i, im_name, max_len, vocab_len, tokenizer, img_predictions)\n",
        "              X_1.append(_X_1)\n",
        "              X_2.append(_X_2)\n",
        "              y.append(_y)\n",
        "  return np.array(X_1), np.array(X_2), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "au5S9nZf5H47"
      },
      "outputs": [],
      "source": [
        "tokenizer = fit_tokenizer(all_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7Md10AQcBJF"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(tokenizer.index_word) + 1\n",
        "vocab_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn0rCaWscMdV"
      },
      "outputs": [],
      "source": [
        "max_len = len(max(create_list(all_dict)))\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_k3LkMP9JJo"
      },
      "outputs": [],
      "source": [
        "cnn_len = predictions[list(predictions.keys())[0]].shape[1]\n",
        "cnn_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8R43LdyxAm3"
      },
      "outputs": [],
      "source": [
        "X_1, X_2, y = convert_all_to_input(all_dict, max_len, vocab_len, tokenizer, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-SSyUHqbtWnI"
      },
      "outputs": [],
      "source": [
        "def shuffle_arrays(arrays, set_seed=-1):\n",
        "    \"\"\"Shuffles arrays in-place, in the same order, along axis=0\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    arrays : List of NumPy arrays.\n",
        "    set_seed : Seed value if int >= 0, else seed is random.\n",
        "    \"\"\"\n",
        "    assert all(len(arr) == len(arrays[0]) for arr in arrays)\n",
        "    seed = np.random.randint(0, 2**(32 - 1) - 1) if set_seed < 0 else set_seed\n",
        "\n",
        "    for arr in arrays:\n",
        "        rstate = np.random.RandomState(seed)\n",
        "        rstate.shuffle(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rO0IPyDhCA-f"
      },
      "outputs": [],
      "source": [
        "shuffle_arrays([X_1, X_2, y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UBxn7vWnd_tC"
      },
      "outputs": [],
      "source": [
        "def create_model(cnn_len, max_len, vocab_len):\n",
        "  cnn_in = Input(shape=(cnn_len,))\n",
        "  cnn_x = Dropout(0.5)(cnn_in)\n",
        "  cnn_out = Dense(units=256, activation='relu')(cnn_x)\n",
        "\n",
        "  lstm_in = Input(shape=(max_len,))\n",
        "  lstm_x = Embedding(vocab_len, 256, mask_zero=True)(lstm_in)\n",
        "  lstm_x = Dropout(0.5)(lstm_x)\n",
        "  lstm_out = LSTM(256)(lstm_x)\n",
        "\n",
        "  combined = add([cnn_out, lstm_out])\n",
        "  combined_x = Dense(units=256, activation='relu')(combined)\n",
        "  output = Dense(units=vocab_len, activation='softmax')(combined_x)\n",
        "\n",
        "  model = Model(inputs=[cnn_in, lstm_in], outputs=output)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zhYruT46eP_y"
      },
      "outputs": [],
      "source": [
        "model = create_model(cnn_len, max_len, vocab_len)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
        "            loss=tf.keras.losses.categorical_crossentropy, \n",
        "            metrics=[tf.keras.metrics.categorical_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sQxkPuse34f"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3Keb5E5xgW0"
      },
      "outputs": [],
      "source": [
        "# Train 4096 rows at a time to avoid memory overflow.\n",
        "\n",
        "batch_size=4096\n",
        "\n",
        "for i in tqdm(range(0, len(X_1), batch_size)):\n",
        "  model.fit(x=[X_1[i:i+batch_size], X_2[i:i+batch_size]], y=y[i:i+batch_size], epochs=20, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdYaptxIipa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bZZm5Bia4fn"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "nGJQv2CSRw0w"
      },
      "outputs": [],
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\t\n",
        "\treturn None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5hcgP-o_RAm3"
      },
      "outputs": [],
      "source": [
        "def generate_desc(model, tokenizer, photo, max_len):\n",
        "\t\n",
        "\tstart_text = 'startseq'\n",
        "\n",
        "\tfor i in range(max_len):\n",
        "\n",
        "\t\ttokens = tokenizer.texts_to_sequences([start_text])[0]\n",
        "\n",
        "\t\ttokens = pad_sequences([tokens], maxlen=max_len)\n",
        "\n",
        "\t\tpred = model.predict([photo, tokens], verbose=0)\n",
        "\n",
        "\t\tpred = np.argmax(pred)\n",
        "\n",
        "\t\tword = word_for_id(pred, tokenizer)\n",
        "\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tstart_text += ' ' + word\n",
        "\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\n",
        "\treturn start_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpQBIvWA-fFi"
      },
      "outputs": [],
      "source": [
        "!wget https://yt3.ggpht.com/9Eiy_C42-Cqiv2-PkhQ0DuElWcZEW6KOivNLDriocMBRe297UMcXwbOwSZedGATnb8IBnkCE0A=s900-c-k-c0x00ffffff-no-rj > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM0vuM2agMjc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "img = Image.open('Bri-design-china-name.png')\n",
        "img2 = img.copy()\n",
        "img = img.resize((299,299))\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img/127.5\n",
        "img = img - 1.0\n",
        "pred = xcep.predict(img)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img2)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "caption = generate_desc(model, tokenizer, pred, vocab_len)\n",
        "caption = caption.strip('startseq').strip('endseq')\n",
        "print(caption)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ_9ed3kXGPm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}